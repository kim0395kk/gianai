import streamlit as st
import google.generativeai as genai
from groq import Groq
from serpapi import GoogleSearch
from supabase import create_client
import json, re, time
from datetime import datetime, timedelta

# ==========================================
# 1. ë””ìì¸ ë° ìŠ¤íƒ€ì¼
# ==========================================
st.set_page_config(layout="wide", page_title="AI Bureau: The Legal Glass", page_icon="âš–ï¸")
st.markdown("""
<style>
    .stApp { background-color: #f3f4f6; }
    .paper-sheet { background: white; padding: 25mm; margin: auto; box-shadow: 0 10px 30px rgba(0,0,0,0.1); font-family: 'Batang', serif; position: relative; }
    .doc-header { text-align: center; font-size: 22pt; font-weight: 900; margin-bottom: 30px; }
    .doc-info { display: flex; justify-content: space-between; border-bottom: 2px solid #333; padding-bottom: 10px; margin-bottom: 20px; }
    .doc-body { font-size: 12pt; text-align: justify; white-space: pre-line; }
    .doc-footer { text-align: center; font-size: 20pt; font-weight: bold; margin-top: 80px; }
    .stamp { position: absolute; bottom: 85px; right: 80px; border: 3px solid #cc0000; color: #cc0000; padding: 5px 10px; font-weight: bold; transform: rotate(-15deg); border-radius: 5px; }
    .agent-log { font-family: 'Consolas', monospace; font-size: 0.85rem; padding: 8px; border-radius: 6px; margin-bottom: 5px; border-left: 4px solid #ddd; background: white; }
    .log-legal { border-color: #3b82f6; color: #1e40af; } 
    .log-search { border-color: #f97316; color: #c2410c; }
    .log-strat { border-color: #8b5cf6; color: #6d28d9; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. ì¸í”„ë¼ ë ˆì´ì–´ (LLM, Search, DB)
# ==========================================

class LLMService:
    def __init__(self):
        self.gemini_models = ["gemini-3-flash", "gemini-2.5-flash", "gemini-2.0-flash-lite"]
        if st.secrets.get("general", {}).get("GEMINI_API_KEY"):
            genai.configure(api_key=st.secrets["general"]["GEMINI_API_KEY"])
        self.groq_client = Groq(api_key=st.secrets["general"]["GROQ_API_KEY"]) if st.secrets.get("general", {}).get("GROQ_API_KEY") else None

    def _try_gemini(self, prompt, is_json=False):
        for model_name in self.gemini_models:
            try:
                model = genai.GenerativeModel(model_name)
                config = genai.GenerationConfig(response_mime_type="application/json") if is_json else None
                res = model.generate_content(prompt, generation_config=config)
                return res.text, model_name
            except: continue
        raise Exception("All Gemini models failed")

    def generate_text(self, prompt):
        try: return self._try_gemini(prompt, False)
        except: 
            if self.groq_client:
                res = self.groq_client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": "user", "content": prompt}]).choices[0].message.content
                return res, "Groq(Llama-3.3)"
            return "ì—°ê²° ì‹¤íŒ¨", "None"

    def generate_json(self, prompt):
        try:
            text, model = self._try_gemini(prompt, True)
            return json.loads(text), model
        except:
            text, model = self.generate_text(prompt + "\nOutput strictly in JSON { ... }")
            match = re.search(r'\{.*\}', text, re.DOTALL)
            return (json.loads(match.group(0)) if match else None), "Fallback/Groq"

class SearchService:
    """[ë³µêµ¬ ì™„ë£Œ] Google Search API (SerpApi) Wrapper"""
    def __init__(self):
        self.api_key = st.secrets["general"].get("SERPAPI_KEY")

    def search_precedents(self, query):
        if not self.api_key:
            return "âš ï¸ ê²€ìƒ‰ API í‚¤(SERPAPI_KEY)ê°€ ì—†ì–´ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        try:
            search_query = f"{query} í–‰ì •ì²˜ë¶„ íŒë¡€ ì‚¬ë¡€ ë¯¼ì› ë‹µë³€"
            params = {"engine": "google", "q": search_query, "api_key": self.api_key, "num": 3, "hl": "ko", "gl": "kr"}
            search = GoogleSearch(params)
            results = search.get_dict().get("organic_results", [])
            if not results: return "ê´€ë ¨ëœ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
            summary = [f"- **[{item.get('title')}]({item.get('link')})**: {item.get('snippet')}" for item in results]
            return "\n".join(summary)
        except Exception as e: return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

class DatabaseService:
    def __init__(self):
        try:
            self.client = create_client(st.secrets["supabase"]["SUPABASE_URL"], st.secrets["supabase"]["SUPABASE_KEY"])
            self.is_active = True
        except: self.is_active = False

    def get_usage_stats(self):
        if not self.is_active: return 0, 0
        try:
            total = self.client.table("law_reports").select("id", count="exact").execute().count
            today = datetime.now().strftime('%Y-%m-%d')
            today_cnt = self.client.table("law_reports").select("id", count="exact").gte("created_at", f"{today}T00:00:00").execute().count
            return today_cnt or 0, total or 0
        except: return 0, 0

    def save_log(self, situation, law, strategy, doc):
        if not self.is_active: return "DB ë¯¸ì—°ê²°"
        try:
            self.client.table("law_reports").insert({"situation": situation, "law_name": law, "summary": json.dumps({"strat": strategy, "doc": doc}, ensure_ascii=False)}).execute()
            return "ì €ì¥ ì„±ê³µ"
        except Exception as e: return f"ì‹¤íŒ¨: {e}"

llm_service, search_service, db_service = LLMService(), SearchService(), DatabaseService()

# ==========================================
# 3. ë„ë©”ì¸ ë ˆì´ì–´ (SPL í”„ë¡¬í”„íŠ¸ ë³´ì¡´ êµ¬ì—­)
# ==========================================
class LegalAgents:
    @staticmethod
    def researcher(situation):
    """Step 1: ë²•ë ¹ íƒìƒ‰ (ê°€ì¤‘ì¹˜ ìˆœ ìµœëŒ€ 3ê°œ)"""
    prompt = f"""
        Role: ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ í–‰ì • ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        Task: ì•„ë˜ ìƒí™©ì— ì ìš©ë  ë²•ë ¹ëª…ê³¼ ì¡°í•­ ë²ˆí˜¸ë¥¼ ì •í™•íˆ ì°¾ì•„ ì„¤ëª…í•˜ì„¸ìš”.
        
        [ì¶œë ¥ ì œì•½ì‚¬í•­ - ë§¤ìš° ì¤‘ìš”]
        1. ë‹¹ì‹ ì´ ëˆ„êµ¬ì¸ì§€(ì˜ˆ: "30ë…„ ê²½ë ¥ ì „ë¬¸ê°€ë¡œì„œ...") ì ˆëŒ€ ë§í•˜ì§€ ë§ˆì„¸ìš”.
        2. ì¸ì‚¿ë§ì´ë‚˜ ì‚¬ì¡± ì—†ì´, **ë°”ë¡œ ë²•ë ¹ëª…ê³¼ ë‚´ìš©ë¶€í„°** ì¶œë ¥í•˜ì„¸ìš”.
        3. ë§íˆ¬ëŠ” ì •ì¤‘í•˜ê³  ê±´ì¡°í•œ í–‰ì •ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ì„¸ìš”.
        
        <instruction>
        ìƒí™©: "{situation}"
        ìœ„ ìƒí™©ì— ì ìš© ê°€ëŠ¥í•œ ë²•ë ¹ì„ **ìƒí™©ê³¼ì˜ ë°€ì ‘ì„±(ê°€ì¤‘ì¹˜)ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìµœëŒ€ 3ê°œ**ë¥¼ ì°¾ìœ¼ì‹œì˜¤.
        ë°˜ë“œì‹œ í˜„í–‰ ëŒ€í•œë¯¼êµ­ ë²•ë ¹ì´ì–´ì•¼ í•˜ë©°, ê° ì¡°í•­ë³„ë¡œ ì„ íƒí•œ ì´ìœ (ì ìš© ê·¼ê±°)ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ë§ë¶™ì´ì‹œì˜¤.
        
        [ì¶œë ¥ í˜•ì‹]
        1. ë²•ë ¹ëª… ì œ00ì¡°(ì¡°í•­ì œëª©): (ì ìš© ê·¼ê±°)
        2. ë²•ë ¹ëª… ì œ00ì¡°(ì¡°í•­ì œëª©): (ì ìš© ê·¼ê±°)
        
        *ì£¼ì˜: ì…ë ¥ì— ì‹¤ëª… ë“± ê°œì¸ì •ë³´ê°€ ìˆë‹¤ë©´ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì²˜ë¦¬í•˜ì„¸ìš”.
        </instruction>
        """"
        return llm_service.generate_text(prompt)

    @staticmethod
    def strategist(situation, legal_basis, search_results):
        prompt = f"""
        ë‹¹ì‹ ì€ í–‰ì • ì—…ë¬´ ë² í…Œë‘ 'ì£¼ë¬´ê´€'ì…ë‹ˆë‹¤.
        [ë¯¼ì› ìƒí™©]: {situation} / [ë²•ì  ê·¼ê±°]: {legal_basis} / [ìœ ì‚¬ ì‚¬ë¡€]: {search_results}
        ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”: 1. ì²˜ë¦¬ ë°©í–¥ 2. í•µì‹¬ ì£¼ì˜ì‚¬í•­ 3. ì˜ˆìƒ ë°˜ë°œ ë° ëŒ€ì‘
        """
        return llm_service.generate_text(prompt)

    @staticmethod
    def drafter(situation, law, meta, strategy):
        prompt = f"ê¸°ì•ˆë¬¸ ì‘ì„±. ìƒí™©:{situation}, ë²•:{law}, ì „ëµ:{strategy}. ì‹œí–‰ì¼:{meta['today_str']}. JSON{{title, receiver, body_paragraphs[], department_head}} ë°˜í™˜."
        return llm_service.generate_json(prompt)

# ==========================================
# 4. ì›Œí¬í”Œë¡œìš° (ì¸ì ì „ë‹¬ ë° íŠœí”Œ ì–¸íŒ¨í‚¹ ìˆ˜ì • ì™„ë£Œ)
# ==========================================
def run_workflow(user_input, dept, officer):
    log_placeholder, model_usage = st.empty(), {}
    st.session_state.logs = [] 

    def add_log(msg, style="sys"):
        st.session_state.logs.append(f"<div class='agent-log log-{style}'>{msg}</div>")
        log_placeholder.markdown("".join(st.session_state.logs), unsafe_allow_html=True)
        time.sleep(0.1)

    # Phase 1: Research
    add_log("ğŸ” Phase 1: ë²•ë ¹ ë¦¬ì„œì¹˜ ì¤‘...", "legal")
    law_text, m1 = LegalAgents.researcher(user_input)
    model_usage['ë¦¬ì„œì¹˜'] = m1
    
    # Phase 1-2: Google Search [ë³µêµ¬ëœ í´ë˜ìŠ¤ ì‚¬ìš©]
    add_log("ğŸŒ êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ ê°€ë™ (ìœ ì‚¬ ì‚¬ë¡€ ìˆ˜ì§‘)...", "search")
    search_res = search_service.search_precedents(user_input)

    # Phase 2: Strategy (ê²€ìƒ‰ ê²°ê³¼ ì „ë‹¬)
    add_log("ğŸ§  Phase 2: ì—…ë¬´ ì „ëµ ìˆ˜ë¦½...", "strat")
    strat_text, m2 = LegalAgents.strategist(user_input, law_text, search_res)
    model_usage['ì „ëµ'] = m2

    # Phase 3: Drafting
    add_log("âœï¸ Phase 3: ê³µë¬¸ì„œ ì‘ì„± ì¤‘...", "sys")
    today = datetime.now()
    meta = {"today_str": today.strftime("%Y. %m. %d."), "doc_num": f"í–‰ì •-{today.year}-{int(time.time())%1000:03d}í˜¸"}
    doc_data, m3 = LegalAgents.drafter(user_input, law_text, meta, strat_text)
    model_usage['ì‘ì„±'] = m3

    # Step 4: DB ì €ì¥ ë° í†µê³„
    save_msg = db_service.save_log(user_input, law_text, strat_text, doc_data)
    tokens = int(len(user_input + law_text + strat_text + str(doc_data)) * 1.5)
    
    log_placeholder.empty()
    return {"doc": doc_data, "meta": meta, "law": law_text, "search": search_res, "strat": strat_text, "model_usage": model_usage, "tokens": tokens, "save_msg": save_msg}

# ==========================================
# 5. UI ë©”ì¸ ë ˆì´ì•„ì›ƒ
# ==========================================
def main():
    st.session_state.setdefault("dept", "ì¶©ì£¼ì‹œì²­ â—‹â—‹ê³¼"); st.session_state.setdefault("officer", "ì´ì£¼ë¬´ê´€")
    col_l, col_r = st.columns([1, 1.2])

    with col_l:
        st.title("ğŸ¢ AI í–‰ì •ê´€ Pro")
        with st.expander("ğŸ‘¤ ë‹´ë‹¹ì ì„¤ì •"):
            st.text_input("ë¶€ì„œ", key="dept"); st.text_input("ì´ë¦„", key="officer")
        user_input = st.text_area("ì—…ë¬´ ì§€ì‹œ", height=150, placeholder="ë¯¼ì› ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
        
        if st.button("ğŸš€ ì‹¤í–‰", type="primary", use_container_width=True):
            if not user_input: st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else: st.session_state['res'] = run_workflow(user_input, st.session_state.dept, st.session_state.officer)

        if 'res' in st.session_state:
            res = st.session_state['res']
            st.markdown("---")
            today_cnt, total_cnt = db_service.get_usage_stats()
            c1, c2, c3 = st.columns(3)
            c1.metric("ì´ë²ˆ í† í°", f"{res['tokens']:,}"); c2.metric("ì˜¤ëŠ˜ ì²˜ë¦¬", f"{today_cnt}ê±´"); c3.metric("ëˆ„ì  ì²˜ë¦¬", f"{total_cnt}ê±´")
            
            with st.expander("ğŸ“Š ì‘ì—… ëª¨ë¸ ì¶”ì ", expanded=True):
                for step, model in res['model_usage'].items(): st.write(f"**{step}**: {model}")
            with st.expander("ğŸŒ ìœ ì‚¬ ì‚¬ë¡€ ê²°ê³¼", expanded=False): st.info(res['search'])

    with col_r:
        if 'res' in st.session_state:
            res = st.session_state['res']
            doc, meta = res['doc'], res['meta']
            st.markdown(f"""
            <div class="paper-sheet">
                <div class="stamp">ì§ì¸ìƒëµ</div>
                <div class="doc-header">{doc.get('title')}</div>
                <div class="doc-info"><span>ë²ˆí˜¸: {meta['doc_num']}</span><span>ì¼ì: {meta['today_str']}</span><span>ìˆ˜ì‹ : {doc.get('receiver')}</span></div>
                <div class="doc-body">{"".join([f"<p>{p}</p>" for p in doc.get('body_paragraphs', [])])}</div>
                <div class="doc-footer">{doc.get('department_head')}</div>
            </div>
            """, unsafe_allow_html=True)

if __name__ == "__main__": main()
