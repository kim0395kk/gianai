import streamlit as st
import requests
import xml.etree.ElementTree as ET
import google.generativeai as genai
import json
import re
from supabase import create_client, Client

# --- 1. ì„¤ì • ë° ì´ˆê¸°í™” ---
st.set_page_config(layout="wide", page_title="í–‰ì •ì—…ë¬´ ë‚´ë¹„ê²Œì´ì…˜")

try:
    GEMINI_API_KEY = st.secrets["general"]["GEMINI_API_KEY"]
    LAW_API_ID = st.secrets["general"]["LAW_API_ID"]
    SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
    
    genai.configure(api_key=GEMINI_API_KEY)
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    st.error(f"ğŸš¨ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# --- 2. ëª¨ë¸ ì„¤ì • (ì—ëŸ¬ ì›ì¸ í•´ê²° íŒŒíŠ¸) ---
def get_valid_model_name():
    """API í‚¤ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•˜ì—¬ ìœ íš¨í•œ ëª¨ë¸ëª…ì„ ë°˜í™˜"""
    try:
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        preferred_order = [
            'models/gemini-1.5-flash',
            'models/gemini-1.5-flash-latest',
            'models/gemini-1.5-pro',
            'models/gemini-1.0-pro',
            'models/gemini-pro'
        ]
        
        for p in preferred_order:
            if p in available_models:
                return p, available_models
        
        if available_models:
            return available_models[0], available_models
            
        return None, []
    except Exception as e:
        return None, []

# ì „ì—­ ë³€ìˆ˜ ì„¤ì •
CURRENT_MODEL_NAME, ALL_MODELS_LIST = get_valid_model_name()

# --- 3. ë¡œì§ í•¨ìˆ˜ (ìˆ˜ì •ë¨: model_nameì„ ì¸ìë¡œ ë°›ìŒ) ---

@st.cache_data(ttl=3600)
def search_law_name(situation, model_name):
    """
    [ìˆ˜ì •ë¨] model_nameì„ ì¸ìë¡œ ë°›ì•„ì„œ NameError ë°©ì§€
    """
    if not model_name: return "ëª¨ë¸ ì˜¤ë¥˜"
    
    model = genai.GenerativeModel(model_name)
    prompt = f"""
    ìƒí™©: {situation}
    
    ìœ„ ìƒí™©ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì°¸ê³ í•´ì•¼ í•  ëŒ€í•œë¯¼êµ­ í˜„í–‰ ë²•ë ¹ì˜ 'ì •ì‹ ëª…ì¹­' 1ê°œë§Œ ì¶œë ¥í•´.
    ì•½ì¹­ì´ë‚˜ ë‹¨ìˆœ ëª…ì‚¬ê°€ ì•„ë‹ˆë¼ ë°˜ë“œì‹œ 'ë²•'ìœ¼ë¡œ ëë‚˜ëŠ” ì „ì²´ ì´ë¦„ì„ ì¨ì•¼ í•´.
    (ë‚˜ìœ ì˜ˆ: ë„ë¡œ, êµí†µ, ì£¼ì°¨ / ì¢‹ì€ ì˜ˆ: ë„ë¡œêµí†µë²•, ì£¼ì°¨ì¥ë²•, ê±´ì¶•ë²•)
    """
    
    try:
        response = model.generate_content(
            prompt,
            generation_config={"max_output_tokens": 30, "temperature": 0.0}
        )
        return response.text.strip()
    except Exception as e:
        return f"ì—ëŸ¬: {str(e)}"

def fetch_and_filter_articles(law_name, situation_keywords):
    """[Python ë¡œì§] ì¡°ë¬¸ í•„í„°ë§ (ì•ˆì „ì¥ì¹˜ í¬í•¨)"""
    try:
        # 1. ë²•ë ¹ ê²€ìƒ‰
        search_url = f"https://www.law.go.kr/DRF/lawSearch.do?OC={LAW_API_ID}&target=law&type=XML&query={law_name}"
        res = requests.get(search_url, timeout=5)
        root = ET.fromstring(res.content)
        
        law_node = root.find(".//law")
        if law_node is None: return None, None
        
        mst = law_node.find("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸").text
        full_name = law_node.find("ë²•ë ¹ëª…í•œê¸€").text

        # 2. ì¡°ë¬¸ ìƒì„¸ ì¡°íšŒ
        detail_url = f"https://www.law.go.kr/DRF/lawService.do?OC={LAW_API_ID}&target=law&MST={mst}&type=XML"
        res = requests.get(detail_url, timeout=10)
        root = ET.fromstring(res.content)
        
        keywords = set(situation_keywords.replace(" ", ",").split(","))
        scored = []
        all_articles = []
        
        for a in root.findall(".//ì¡°ë¬¸"):
            cont = a.find('ì¡°ë¬¸ë‚´ìš©').text or ""
            num = a.find('ì¡°ë¬¸ë²ˆí˜¸').text or ""
            text = f"ì œ{num}ì¡°: {cont}"
            all_articles.append(text)
            
            score = sum(1 for k in keywords if len(k) > 1 and k in cont)
            if score > 0:
                scored.append((score, text))
        
        # 1ìˆœìœ„: í‚¤ì›Œë“œ ë§¤ì¹­, 2ìˆœìœ„: ë‹¨ìˆœ ìƒìœ„ ì¡°ë¬¸ (Fallback)
        if scored:
            scored.sort(key=lambda x: x[0], reverse=True)
            return full_name, "\n".join([x[1] for x in scored[:5]])
        elif all_articles:
            return full_name, "\n".join(all_articles[:5])
        else:
            return None, None
            
    except Exception as e:
        return None, None

def generate_report(situation, law_name, context, model_name):
    """
    [ìˆ˜ì •ë¨] model_nameì„ ì¸ìë¡œ ë°›ì•„ì„œ NameError ë°©ì§€
    """
    if not context or not model_name: return None
    
    model = genai.GenerativeModel(model_name)
    prompt = f"""
    ìƒí™©: {situation}
    ë²•ë ¹: {context}
    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'summary'(ìš”ì•½), 'steps'(ë‹¨ê³„ë³„ ëŒ€ì‘ ë°°ì—´), 'tip'(íŒ)ì„ í¬í•¨í•œ JSONì„ ì‘ì„±í•˜ë¼.
    """
    try:
        res = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(res.text)
    except: return None

# --- 4. UI ---

st.title("âš¡ï¸ ì´ˆíš¨ìœ¨ ê³µë¬´ì› AI ì–´ì‹œìŠ¤í„´íŠ¸")

# ì‚¬ì´ë“œë°” ìƒíƒœ í‘œì‹œ
with st.sidebar:
    st.header("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    if CURRENT_MODEL_NAME:
        st.success(f"âœ… ì—°ê²° ì„±ê³µ: {CURRENT_MODEL_NAME}")
    else:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ (API í‚¤ í™•ì¸ í•„ìš”)")
        
    with st.expander("ëª¨ë¸ ì „ì²´ ë¦¬ìŠ¤íŠ¸"):
        st.write(ALL_MODELS_LIST)

user_input = st.text_area("ë¯¼ì› ë‚´ìš© ì…ë ¥", height=100, placeholder="ì˜ˆ: ì¸ë„ ìœ„ ë¶ˆë²• ì£¼ì •ì°¨ ë‹¨ì† ê·¼ê±°")

if st.button("ë¶„ì„ ì‹¤í–‰", type="primary"):
    if not user_input or not CURRENT_MODEL_NAME:
        st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ ëª¨ë¸ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        with st.status("ë¶„ì„ ì¤‘...") as status:
            # 1. ë²•ë ¹ íƒìƒ‰ (ì¸ìë¡œ ëª¨ë¸ëª… ì „ë‹¬)
            status.write("1. ë²•ë ¹ íƒìƒ‰...")
            inferred = search_law_name(user_input, CURRENT_MODEL_NAME)
            
            if "ì—ëŸ¬" in inferred:
                st.error(f"API ì—ëŸ¬: {inferred}")
                st.stop()
                
            clean_name = re.sub(r'[^ê°€-í£]', '', inferred)
            
            # 2. ì¡°ë¬¸ ì¶”ì¶œ
            status.write(f"2. {clean_name} ì¡°ë¬¸ ì¶”ì¶œ...")
            full_name, context = fetch_and_filter_articles(clean_name, user_input)
            
            if context:
                # 3. ë¦¬í¬íŠ¸ ìƒì„± (ì¸ìë¡œ ëª¨ë¸ëª… ì „ë‹¬)
                status.write("3. ë¦¬í¬íŠ¸ ìƒì„±...")
                res = generate_report(user_input, full_name, context, CURRENT_MODEL_NAME)
                
                if res:
                    status.update(label="ì™„ë£Œ", state="complete")
                    st.divider()
                    st.success(f"ğŸ“Œ {full_name}")
                    st.write(res.get('summary'))
                    for s in res.get('steps', []):
                        st.info(f"**{s['title']}**: {s['desc']}")
                    st.warning(f"íŒ: {res.get('tip')}")
                    
                    try:
                        supabase.table("law_reports").insert({
                            "situation": user_input, "law_name": full_name,
                            "summary": res['summary'], "tip": res['tip']
                        }).execute()
                    except: pass
            else:
                st.error(f"'{clean_name}'ì— ëŒ€í•œ ì¡°ë¬¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
