import streamlit as st
import requests
import xml.etree.ElementTree as ET
import google.generativeai as genai
import json
import re
from supabase import create_client, Client

# --- 1. ì„¤ì • ë° ìºì‹± (API í˜¸ì¶œ ì ˆì•½) ---
st.set_page_config(layout="wide", page_title="í–‰ì •ì—…ë¬´ ë‚´ë¹„ê²Œì´ì…˜")

# Streamlit Secrets ë¡œë“œ
try:
    GEMINI_API_KEY = st.secrets["general"]["GEMINI_API_KEY"]
    LAW_API_ID = st.secrets["general"]["LAW_API_ID"]
    SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
    
    genai.configure(api_key=GEMINI_API_KEY)
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    st.error(f"ğŸš¨ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# --- 2. ìµœì í™”ëœ ì—”ì§„ ---

@st.cache_data(ttl=3600) # 1ì‹œê°„ ë™ì•ˆ ë™ì¼ ì§ˆë¬¸ ìºì‹± (API ë¹„ìš© 0ì› ë§Œë“¤ê¸°)
def search_law_name(situation):
    """
    [AI 1ë‹¨ê³„] ìƒí™©ì—ì„œ ê°€ì¥ ìœ ë ¥í•œ ë²•ë ¹ëª… 1ê°œë§Œ ì¶”ë¡  (ì…ë ¥ í† í° ìµœì†Œí™”)
    """
    model = genai.GenerativeModel('gemini-3-flash')
    # Prompt Engineering: ë‹¤ë¥¸ ë§ ì—†ì´ ë²•ë ¹ëª…ë§Œ ë”± ë±‰ê²Œ í•˜ì—¬ ì¶œë ¥ í† í° ì ˆì•½
    prompt = f"ìƒí™©: {situation}\nìœ„ ìƒí™©ì— ì ìš©ë˜ëŠ” ê°€ì¥ í•µì‹¬ì ì¸ ë²•ë ¹ ì´ë¦„ í•˜ë‚˜ë§Œ ì •í™•í•œ í•œêµ­ì–´ ëª…ì¹­ìœ¼ë¡œ ì¶œë ¥í•´. (ì˜ˆ: ë„ë¡œêµí†µë²•)"
    response = model.generate_content(
        prompt,
        generation_config={"max_output_tokens": 20, "temperature": 0.0} # Temperature 0ìœ¼ë¡œ í™˜ê° ë°©ì§€
    )
    return response.text.strip()

def fetch_and_filter_articles(law_name, situation_keywords):
    """
    [Python ë¡œì§] AI ëŒ€ì‹  Pythonì´ ì¡°ë¬¸ì„ í•„í„°ë§í•©ë‹ˆë‹¤. (í† í° ë¹„ìš© 0ì›)
    - ë²•ë ¹ì˜ ëª¨ë“  ì¡°ë¬¸ì„ ê°€ì ¸ì˜¨ ë’¤, ì‚¬ìš©ì ìƒí™©(keyword)ê³¼ ë§¤ì¹­ë˜ëŠ” ì¡°ë¬¸ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    """
    # 1. ë²•ë ¹ ê²€ìƒ‰ ë° MST í™•ë³´
    search_url = f"https://www.law.go.kr/DRF/lawSearch.do?OC={LAW_API_ID}&target=law&type=XML&query={law_name}"
    try:
        res = requests.get(search_url, timeout=5)
        root = ET.fromstring(res.content)
        law_node = root.find(".//law")
        if law_node is None: return None, None
        
        mst = law_node.find("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸").text
        full_name = law_node.find("ë²•ë ¹ëª…í•œê¸€").text
    except: return None, None

    # 2. ìƒì„¸ ì¡°ë¬¸ ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ)
    detail_url = f"https://www.law.go.kr/DRF/lawService.do?OC={LAW_API_ID}&target=law&MST={mst}&type=XML"
    try:
        res = requests.get(detail_url, timeout=10)
        root = ET.fromstring(res.content)
        
        # 3. [í•µì‹¬] í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ (RAG ìœ ì‚¬ ë°©ì‹)
        # ì‚¬ìš©ì ìƒí™©ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ì¡°ë¬¸ê³¼ ë¹„êµ
        keywords = set(situation_keywords.replace(" ", ",").split(",")) 
        scored_articles = []
        
        for a in root.findall(".//ì¡°ë¬¸"):
            num = a.find('ì¡°ë¬¸ë²ˆí˜¸').text or ""
            cont = a.find('ì¡°ë¬¸ë‚´ìš©').text or ""
            
            # ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜: ìƒí™© í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¡°ë¬¸ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬
            score = 0
            for k in keywords:
                if len(k) > 1 and k in cont: # 2ê¸€ì ì´ìƒ í‚¤ì›Œë“œë§Œ
                    score += 1
            
            # ì ìˆ˜ê°€ ìˆê±°ë‚˜, í•µì‹¬ ì¡°ë¬¸(ë³´í†µ 100ì¡° ì´ë‚´ì˜ ë²Œì¹™/ê³¼íƒœë£Œ ë“±)ì´ë©´ í›„ë³´ ë“±ë¡
            if score > 0 or ("ì„¤ì¹˜" in cont or "ì œí•œ" in cont or "ê¸ˆì§€" in cont): 
                scored_articles.append((score, f"ì œ{num}ì¡°: {cont}"))
        
        # ê´€ë ¨ë„ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3~5ê°œë§Œ AIì—ê²Œ ì „ë‹¬ (í† í° íšê¸°ì  ì ˆê°)
        scored_articles.sort(key=lambda x: x[0], reverse=True)
        final_context = "\n".join([item[1] for item in scored_articles[:5]])
        
        return full_name, final_context
    except: return None, None

def generate_report(situation, law_name, context):
    """[AI 2ë‹¨ê³„] ì •ì œëœ ë°ì´í„°ë¡œ ë¦¬í¬íŠ¸ ìƒì„±"""
    if not context: return None
    
    model = genai.GenerativeModel('gemini-3-flash')
    
    prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ì°¨ í–‰ì • ë² í…Œë‘ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¼ì› ëŒ€ì‘ ë³´ê³ ì„œë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    
    [ìƒí™©] {situation}
    [í•µì‹¬ ë²•ë ¹ ì¡°ë¬¸]
    {context}
    
    [ì¶œë ¥ í˜•ì‹(JSON Only)]
    {{
        "summary": "ë²•ì  ê·¼ê±° ìš”ì•½ (ê°„ê²°í•˜ê²Œ)",
        "steps": [
            {{"title": "1ë‹¨ê³„: ìƒí™© íŒë‹¨", "desc": "ë‚´ìš©..."}},
            {{"title": "2ë‹¨ê³„: ë²•ì  ê·¼ê±° ì œì‹œ", "desc": "ë‚´ìš©..."}},
            {{"title": "3ë‹¨ê³„: ìµœì¢… ë‹µë³€", "desc": "ë‚´ìš©..."}}
        ],
        "tip": "ì‹¤ë¬´ì íŒ"
    }}
    """
    try:
        response = model.generate_content(
            prompt, 
            generation_config={"response_mime_type": "application/json", "temperature": 0.5}
        )
        return json.loads(response.text)
    except: return None

# --- 3. UI ë° ì‹¤í–‰ ---

st.title("âš¡ï¸ ì´ˆíš¨ìœ¨ ê³µë¬´ì› AI ì–´ì‹œìŠ¤í„´íŠ¸")
st.caption("Python ì „ì²˜ë¦¬ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ AI í† í° ë¹„ìš©ì„ 80% ì ˆê°í–ˆìŠµë‹ˆë‹¤.")

user_input = st.text_area("ë¯¼ì› ë‚´ìš© ì…ë ¥", height=100, placeholder="ì˜ˆ: ì•„íŒŒíŠ¸ ë‹¨ì§€ ë‚´ ë¬´ë‹¨ ë°©ì¹˜ ì°¨ëŸ‰ ê°•ì œ ê²¬ì¸ ê°€ëŠ¥ ì—¬ë¶€")

if st.button("ë¶„ì„ ì‹¤í–‰", type="primary"):
    if not user_input:
        st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.status("âš™ï¸ ì§€ëŠ¥í˜• í”„ë¡œì„¸ìŠ¤ ê°€ë™ ì¤‘...", expanded=True) as status:
            
            # 1. ë²•ë ¹ëª… ì¶”ë¡  (AI ìµœì†Œ ì‚¬ìš©)
            status.write("1. ê´€ë ¨ ë²•ë ¹ íƒìƒ‰ ì¤‘...")
            inferred_law = search_law_name(user_input)
            clean_law_name = re.sub(r'[^ê°€-í£]', '', inferred_law)
            
            # 2. Python í•„í„°ë§ (ë¹„ìš© 0ì›)
            status.write(f"2. [{clean_law_name}] ë‚´ í•µì‹¬ ì¡°ë¬¸ ì¶”ì¶œ ì¤‘...")
            # ì‚¬ìš©ì ì…ë ¥ì˜ ëª…ì‚¬ë“¤ì„ í‚¤ì›Œë“œë¡œ í™œìš©í•´ ì¡°ë¬¸ í•„í„°ë§
            full_law_name, relevant_articles = fetch_and_filter_articles(clean_law_name, user_input)
            
            if relevant_articles:
                # 3. ë¦¬í¬íŠ¸ ìƒì„±
                status.write("3. ìµœì¢… ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘...")
                result = generate_report(user_input, full_law_name, relevant_articles)
                
                if result:
                    status.update(label="ì™„ë£Œ!", state="complete")
                    
                    # ê²°ê³¼ í™”ë©´
                    st.divider()
                    st.success(f"ğŸ“Œ ì ìš© ë²•ë ¹: **{full_law_name}**")
                    st.write(f"â„¹ï¸ **ìš”ì•½**: {result['summary']}")
                    
                    c1, c2 = st.columns(2)
                    with c1:
                        for step in result['steps']:
                            st.subheader(step['title'])
                            st.write(step['desc'])
                    with c2:
                        st.error("ğŸ’¡ ë² í…Œë‘ì˜ í•œë§ˆë””")
                        st.write(result['tip'])
                        
                        with st.expander("ì°¸ì¡°ëœ í•µì‹¬ ì¡°ë¬¸ ë³´ê¸°"):
                            st.code(relevant_articles, language="text")
                    
                    # DB ì €ì¥ (ë¹„ë™ê¸° ì²˜ë¦¬ì²˜ëŸ¼ ë³´ì´ê²Œ ë§ˆì§€ë§‰ì— ë°°ì¹˜)
                    supabase.table("law_reports").insert({
                        "situation": user_input, 
                        "law_name": full_law_name,
                        "summary": result['summary'], 
                        "tip": result['tip']
                    }).execute()
                    
                else:
                    st.error("ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.error(f"'{clean_law_name}'ì—ì„œ ê´€ë ¨ ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
