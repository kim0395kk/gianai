import streamlit as st
import requests
import xml.etree.ElementTree as ET
import google.generativeai as genai
import json
import re
from supabase import create_client, Client

# --- 1. ì„¤ì • ë° ë³´ì•ˆí‚¤ ë¡œë“œ ---
st.set_page_config(layout="wide", page_title="í–‰ì •ì—…ë¬´ ë‚´ë¹„ê²Œì´ì…˜")

try:
    GEMINI_API_KEY = st.secrets["general"]["GEMINI_API_KEY"]
    LAW_API_ID = st.secrets["general"]["LAW_API_ID"]
    SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
    
    genai.configure(api_key=GEMINI_API_KEY)
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    st.error(f"ğŸš¨ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# --- 2. [í•µì‹¬] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ ê°ì§€ í•¨ìˆ˜ ---
@st.cache_data(show_spinner=False)
def get_best_available_model():
    """
    ë‚´ API í‚¤ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ì¤‘ ê°€ì¥ ì¢‹ì€ ê²ƒì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
    404 ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        # 2. ìš°ì„ ìˆœìœ„ ì„¤ì • (ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ìˆœì„œ)
        # ì£¼ì˜: APIì—ì„œëŠ” 'models/' ì ‘ë‘ì‚¬ê°€ ë¶™ëŠ” ê²½ìš°ê°€ ë§ìŒ
        priority_list = [
            'models/gemini-1.5-flash',
            'models/gemini-1.5-flash-latest',
            'models/gemini-1.5-pro',
            'models/gemini-1.0-pro',
            'gemini-1.5-flash', # ì ‘ë‘ì‚¬ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„
        ]

        # 3. êµì§‘í•© ì°¾ê¸° (ìš°ì„ ìˆœìœ„ ëª¨ë¸ì´ ë‚´ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸)
        for target in priority_list:
            if target in available_models:
                return target
        
        # 4. ìš°ì„ ìˆœìœ„ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ëª¨ë¸ ë°˜í™˜ (ìµœí›„ì˜ ìˆ˜ë‹¨)
        if available_models:
            return available_models[0]
        else:
            return None
            
    except Exception as e:
        return None

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ëª… í™•ì •
CURRENT_MODEL_NAME = get_best_available_model()

# --- 3. ìµœì í™”ëœ ì—”ì§„ ---

@st.cache_data(ttl=3600)
def search_law_name(situation):
    """[AI 1ë‹¨ê³„] ë²•ë ¹ëª… ì¶”ë¡  (í”„ë¡¬í”„íŠ¸ ê°•í™” ë²„ì „)"""
    if not CURRENT_MODEL: return "ëª¨ë¸ ì˜¤ë¥˜"
    model = genai.GenerativeModel(CURRENT_MODEL)
    
    # ë³€ê²½ì : 'ë„ë¡œ' ê°™ì€ ë‹¨ë‹µí˜• ë§ê³  'ë„ë¡œêµí†µë²•' ê°™ì€ í’€ë„¤ì„ì„ ìš”êµ¬
    prompt = f"""
    ìƒí™©: {situation}
    
    ìœ„ ìƒí™©ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì°¸ê³ í•´ì•¼ í•  ëŒ€í•œë¯¼êµ­ í˜„í–‰ ë²•ë ¹ì˜ 'ì •ì‹ ëª…ì¹­' 1ê°œë§Œ ì¶œë ¥í•´.
    ì•½ì¹­ì´ë‚˜ ë‹¨ìˆœ ëª…ì‚¬ê°€ ì•„ë‹ˆë¼ ë°˜ë“œì‹œ 'ë²•'ìœ¼ë¡œ ëë‚˜ëŠ” ì „ì²´ ì´ë¦„ì„ ì¨ì•¼ í•´.
    (ë‚˜ìœ ì˜ˆ: ë„ë¡œ, êµí†µ, ì£¼ì°¨ / ì¢‹ì€ ì˜ˆ: ë„ë¡œêµí†µë²•, ì£¼ì°¨ì¥ë²•, ê±´ì¶•ë²•)
    """
    
    try:
        response = model.generate_content(
            prompt,
            generation_config={"max_output_tokens": 30, "temperature": 0.0}
        )
        return response.text.strip()
    except Exception as e:
        return f"ì—ëŸ¬: {str(e)}"
        
def fetch_and_filter_articles(law_name, situation_keywords):
    """[Python ë¡œì§] ì¡°ë¬¸ í•„í„°ë§ (ì•ˆì „ì¥ì¹˜ ì¶”ê°€)"""
    # 1. ë²•ë ¹ ê²€ìƒ‰
    try:
        # ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì •í™•í•œ ëª…ì¹­ìœ¼ë¡œ ìš”ì²­
        search_url = f"https://www.law.go.kr/DRF/lawSearch.do?OC={LAW_API_ID}&target=law&type=XML&query={law_name}"
        res = requests.get(search_url, timeout=5)
        root = ET.fromstring(res.content)
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°, ì²« ë²ˆì§¸ ê²°ê³¼ê°€ ê°€ì¥ ì •í™•í•  í™•ë¥ ì´ ë†’ìŒ
        law_node = root.find(".//law")
        if law_node is None: return None, None
        
        mst = law_node.find("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸").text
        full_name = law_node.find("ë²•ë ¹ëª…í•œê¸€").text
    except Exception as e:
        print(f"ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None, None

    # 2. ì¡°ë¬¸ ê°€ì ¸ì˜¤ê¸°
    try:
        detail_url = f"https://www.law.go.kr/DRF/lawService.do?OC={LAW_API_ID}&target=law&MST={mst}&type=XML"
        res = requests.get(detail_url, timeout=10)
        root = ET.fromstring(res.content)
        
        keywords = set(situation_keywords.replace(" ", ",").split(","))
        scored = []
        
        # ëª¨ë“  ì¡°ë¬¸ ìˆœíšŒ
        all_articles = [] # ì ìˆ˜ê°€ ì—†ì–´ë„ ì¼ë‹¨ ë‹´ì•„ë‘˜ ë¦¬ìŠ¤íŠ¸
        for a in root.findall(".//ì¡°ë¬¸"):
            cont = a.find('ì¡°ë¬¸ë‚´ìš©').text or ""
            num = a.find('ì¡°ë¬¸ë²ˆí˜¸').text or ""
            
            # ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥ (í˜•ì‹: ì œNì¡° ë‚´ìš©)
            article_text = f"ì œ{num}ì¡°: {cont}"
            all_articles.append(article_text)
            
            # ì ìˆ˜ ê³„ì‚°
            score = sum(1 for k in keywords if len(k) > 1 and k in cont)
            if score > 0:
                scored.append((score, article_text))
        
        # [ìˆ˜ì •ëœ ë¡œì§]
        # 1ìˆœìœ„: í‚¤ì›Œë“œê°€ ë§¤ì¹­ëœ ì¡°ë¬¸ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ì“´ë‹¤.
        if scored:
            scored.sort(key=lambda x: x[0], reverse=True)
            return full_name, "\n".join([x[1] for x in scored[:5]])
        
        # 2ìˆœìœ„ (Fallback): í‚¤ì›Œë“œ ë§¤ì¹­ì´ í•˜ë‚˜ë„ ì•ˆ ëìœ¼ë©´, ê·¸ëƒ¥ ì•ë¶€ë¶„ 5ê°œ ì¡°ë¬¸ì´ë¼ë„ ë³´ë‚¸ë‹¤.
        # (AIê°€ 'ë„ë¡œ'ë¼ê³  ì˜ëª» ì°¾ì•˜ì–´ë„, ë‚´ìš©ì€ ë³´ì—¬ì£¼ê¸° ìœ„í•¨)
        elif all_articles:
            return full_name, "\n".join(all_articles[:5])
            
        else:
            return None, None
            
    except Exception as e:
        print(f"ì¡°ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None, None
def generate_report(situation, law_name, context):
    """[AI 2ë‹¨ê³„] ë¦¬í¬íŠ¸ ìƒì„±"""
    if not context or not CURRENT_MODEL_NAME: return None
    
    model = genai.GenerativeModel(CURRENT_MODEL_NAME)
    
    prompt = f"""
    ë‹¹ì‹ ì€ í–‰ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¯¼ì› ëŒ€ì‘ ë³´ê³ ì„œë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    
    [ìƒí™©] {situation}
    [ì°¸ì¡° ì¡°ë¬¸]
    {context}
    
    [JSON í˜•ì‹]
    {{
        "summary": "ë²•ì  ê·¼ê±° ìš”ì•½",
        "steps": [
            {{"title": "ë‹¨ê³„ 1", "desc": "ë‚´ìš©"}},
            {{"title": "ë‹¨ê³„ 2", "desc": "ë‚´ìš©"}},
            {{"title": "ë‹¨ê³„ 3", "desc": "ë‚´ìš©"}}
        ],
        "tip": "ì‹¤ë¬´ íŒ"
    }}
    """
    try:
        response = model.generate_content(
            prompt, 
            generation_config={"response_mime_type": "application/json", "temperature": 0.5}
        )
        return json.loads(response.text)
    except: return None

# --- 4. UI ë° ì‹¤í–‰ ---

st.title("âš¡ï¸ ì´ˆíš¨ìœ¨ ê³µë¬´ì› AI ì–´ì‹œìŠ¤í„´íŠ¸")

# ëª¨ë¸ ì—°ê²° ìƒíƒœ í‘œì‹œ (ì‚¬ì´ë“œë°”)
with st.sidebar:
    if CURRENT_MODEL_NAME:
        st.success(f"âœ… ì—°ê²°ëœ ëª¨ë¸: {CURRENT_MODEL_NAME}")
    else:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

user_input = st.text_area("ë¯¼ì› ë‚´ìš© ì…ë ¥", height=100, placeholder="ì˜ˆ: ì¸ë„ ìœ„ ë¶ˆë²• ì£¼ì •ì°¨ ë‹¨ì† ê·¼ê±°")

if st.button("ë¶„ì„ ì‹¤í–‰", type="primary"):
    if not user_input or not CURRENT_MODEL_NAME:
        st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ ëª¨ë¸ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        with st.status("âš™ï¸ ì§€ëŠ¥í˜• í”„ë¡œì„¸ìŠ¤ ê°€ë™ ì¤‘...", expanded=True) as status:
            
            # 1. ë²•ë ¹ëª… ì¶”ë¡ 
            status.write("1. ê´€ë ¨ ë²•ë ¹ íƒìƒ‰ ì¤‘...")
            inferred_law = search_law_name(user_input)
            
            if "ì—ëŸ¬" in inferred_law or "ì‹¤íŒ¨" in inferred_law:
                st.error(f"AI í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {inferred_law}")
                st.stop()
                
            clean_law_name = re.sub(r'[^ê°€-í£]', '', inferred_law)
            
            # 2. Python í•„í„°ë§
            status.write(f"2. [{clean_law_name}] ë‚´ í•µì‹¬ ì¡°ë¬¸ ì¶”ì¶œ ì¤‘...")
            full_law_name, relevant_articles = fetch_and_filter_articles(clean_law_name, user_input)
            
            if relevant_articles:
                # 3. ë¦¬í¬íŠ¸ ìƒì„±
                status.write("3. ìµœì¢… ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘...")
                result = generate_report(user_input, full_law_name, relevant_articles)
                
                if result:
                    status.update(label="ì™„ë£Œ!", state="complete")
                    
                    st.divider()
                    st.success(f"ğŸ“Œ ì ìš© ë²•ë ¹: **{full_law_name}**")
                    st.write(f"â„¹ï¸ **ìš”ì•½**: {result['summary']}")
                    
                    c1, c2 = st.columns(2)
                    with c1:
                        for step in result['steps']:
                            st.subheader(step['title'])
                            st.write(step['desc'])
                    with c2:
                        st.warning(f"ğŸ’¡ íŒ: {result['tip']}")
                        with st.expander("ì°¸ì¡°ëœ ì¡°ë¬¸"):
                            st.code(relevant_articles, language="text")
                    
                    # DB ì €ì¥
                    try:
                        supabase.table("law_reports").insert({
                            "situation": user_input, 
                            "law_name": full_law_name,
                            "summary": result['summary'], 
                            "tip": result['tip']
                        }).execute()
                    except: pass 
                else:
                    st.error("ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.error(f"'{clean_law_name}' ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ ìˆ˜ì •í•´ë³´ì„¸ìš”.")

