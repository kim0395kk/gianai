import streamlit as st
import requests
import xml.etree.ElementTree as ET
import google.generativeai as genai
from serpapi import GoogleSearch
import re
import time
import json
from supabase import create_client
from groq import Groq 

# --- 0. ë””ìì¸ ë° ì´ˆê¸° ì„¤ì • ---
st.set_page_config(layout="wide", page_title="AI í–‰ì •ê´€: The Legal Glass (Tenbagger Ed.)", page_icon="âš–ï¸")

st.markdown("""
<style>
    .stApp { background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); }
    div[data-testid="stVerticalBlock"] > div[style*="background-color"] {
        background: rgba(255, 255, 255, 0.9);
        box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.1);
        backdrop-filter: blur(8px);
        border-radius: 20px;
        border: 1px solid rgba(255, 255, 255, 0.4);
        padding: 25px;
        margin-bottom: 20px;
    }
    h1, h2, h3 { color: #1a237e !important; font-family: 'Helvetica Neue', sans-serif; }
    strong { color: #1a237e; background-color: rgba(26, 35, 126, 0.1); padding: 2px 4px; border-radius: 4px; }
    .status-badge { background-color: #dbeafe; color: #1e40af; padding: 4px 8px; border-radius: 6px; font-size: 0.8rem; font-weight: bold; }
    .groq-badge { background-color: #fce7f3; color: #9d174d; padding: 4px 8px; border-radius: 6px; font-size: 0.8rem; font-weight: bold; border: 1px solid #fbcfe8; }
</style>
""", unsafe_allow_html=True)

# --- 1. API ì—°ê²° ë° ì˜ˆì™¸ì²˜ë¦¬ ---
try:
    GEMINI_API_KEY = st.secrets["general"]["GEMINI_API_KEY"]
    LAW_API_ID = st.secrets["general"]["LAW_API_ID"]
    SERPAPI_KEY = st.secrets["general"]["SERPAPI_KEY"]
    GROQ_API_KEY = st.secrets["general"].get("GROQ_API_KEY", None)

    try:
        SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
        SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        use_db = True
    except: 
        use_db = False

    genai.configure(api_key=GEMINI_API_KEY)
    
    if GROQ_API_KEY:
        groq_client = Groq(api_key=GROQ_API_KEY)
    else:
        groq_client = None

except Exception as e:
    st.error(f"ğŸš¨ ì‹œìŠ¤í…œ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# ëª¨ë¸ ìš°ì„ ìˆœìœ„ (ìµœì‹  -> ì•ˆì • -> ê³ ì„±ëŠ¥)
GEMINI_PRIORITY_LIST = [
    "gemini-2.0-flash-exp", 
    "gemini-1.5-flash", 
    "gemini-1.5-pro"
]
GROQ_MODEL = "llama-3.3-70b-versatile"

# --- 2. í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ (Smart Fallback) ---
def generate_content_hybrid(prompt, temp=0.1):
    """
    1. Gemini ëª¨ë¸ ìˆœì°¨ ì‹œë„
    2. ì‹¤íŒ¨ ì‹œ Groq(Llama 3.3) ì‹¤í–‰ (ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ ì£¼ì…)
    """
    # 1. Gemini ì‹œë„
    for model_name in GEMINI_PRIORITY_LIST:
        try:
            model = genai.GenerativeModel(model_name)
            # ë¹ ë¥¸ ì „í™˜ì„ ìœ„í•´ íƒ€ì„ì•„ì›ƒ 8ì´ˆ ì„¤ì •
            res = model.generate_content(prompt, request_options={'timeout': 8})
            return res.text, f"Gemini ({model_name})"
        except Exception:
            continue

    # 2. Groq ì‹œë„
    if groq_client:
        try:
            # [ì „ë¬¸ê°€ ëª¨ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸]
            system_role = """
            ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ í–‰ì •ë²• ì „ë¬¸ ë³€í˜¸ì‚¬ì…ë‹ˆë‹¤.
            1. íŒë¡€ì™€ ë²•ë ¹ì— ê¸°ë°˜í•˜ì—¬ ëƒ‰ì² í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
            2. ì¶”ì¸¡ì„± ë°œì–¸ì„ ì‚¼ê°€ê³ , ì£¼ì–´ì§„ ë°ì´í„° ë‚´ì—ì„œ ê·¼ê±°ë¥¼ ì°¾ìœ¼ì‹­ì‹œì˜¤.
            3. ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.
            """
            
            chat_completion = groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": prompt}
                ],
                model=GROQ_MODEL,
                temperature=temp,
                max_completion_tokens=4000
            )
            return chat_completion.choices[0].message.content, "Groq (Llama 3.3 Expert)"
        except Exception as groq_e:
            return f"AI ì‘ë‹µ ì‹¤íŒ¨ (Error: {groq_e})", "Fail"
    else:
        return "Gemini ì—°ê²° ì‹¤íŒ¨ ë° Groq í‚¤ ì—†ìŒ.", "Fail"

# --- 3. [Tenbagger Logic] ë²•ë ¹ íŒë‹¨ ë° ê²€ìƒ‰ ê°•í™” ---

def search_candidates_from_api(keywords):
    """[Action] í‚¤ì›Œë“œë¡œ APIë¥¼ ì‹¤ì œ ê²€ìƒ‰í•˜ì—¬ ì‹¤ì¡´ ë²•ë ¹ëª… í›„ë³´ í™•ë³´"""
    candidates = set()
    for kw in keywords:
        if not kw or len(kw) < 2: continue # ë„ˆë¬´ ì§§ì€ í‚¤ì›Œë“œ ë¬´ì‹œ
        try:
            url = f"https://www.law.go.kr/DRF/lawSearch.do?OC={LAW_API_ID}&target=law&type=XML&query={kw}&display=3"
            res = requests.get(url, timeout=3)
            root = ET.fromstring(res.content)
            for law in root.findall(".//law"):
                candidates.add(law.find("ë²•ë ¹ëª…í•œê¸€").text)
        except: continue
    return list(candidates)

def get_law_context_advanced(situation, callback):
    """
    [Reasoning -> Action -> Selection] + [Fail-Safe Strategy]
    Llamaê°€ ë©ì²­í•˜ê²Œ êµ´ì–´ë„ ì½”ë“œë¡œ ë³´ì •í•˜ì—¬ ë°˜ë“œì‹œ ë²•ë ¹ì„ ì°¾ì•„ë‚´ëŠ” ë¡œì§
    """
    callback(10, "ğŸ¤” ë²•ë¥  ìŸì  ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
    
    # 1. [Reasoning] JSON í¬ë§· ê°•ì œ
    prompt_kw = f"""
    ìƒí™©: {situation}
    
    ìœ„ ìƒí™©ê³¼ ê´€ë ¨ëœ ëŒ€í•œë¯¼êµ­ ë²•ë ¹ ê²€ìƒ‰ìš© 'í•µì‹¬ í‚¤ì›Œë“œ' 3~4ê°œë¥¼ ì¶”ì¶œí•´.
    1. êµ¬ì²´ì  í‚¤ì›Œë“œ (ì˜ˆ: ì „ë™í‚¥ë³´ë“œ, ì¸µê°„ì†ŒìŒ)
    2. í¬ê´„ì  í‚¤ì›Œë“œ (ì˜ˆ: ê³µë™ì£¼íƒê´€ë¦¬ë²•, ë„ë¡œêµí†µë²•, ê²½ë²”ì£„ì²˜ë²Œë²•)
    
    ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´. ì„¤ëª… ê¸ˆì§€.
    {{
        "keywords": ["ë‹¨ì–´1", "ë‹¨ì–´2", "ë‹¨ì–´3"]
    }}
    """
    
    keywords_json, model_src = generate_content_hybrid(prompt_kw)
    
    # [Parsing] JSON íŒŒì‹± ë° ì •ì œ
    try:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (Backtick ì œê±°)
        json_match = re.search(r'\{.*\}', keywords_json, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            keywords = json.loads(json_str).get("keywords", [])
        else:
            raise ValueError("No JSON found")
    except:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ìœ¼ë¡œ í•œê¸€ ë‹¨ì–´ë§Œ ê°•ì œ ì¶”ì¶œ (ë¹„ìƒ ì¡°ì¹˜)
        keywords = re.findall(r'[ê°€-í£]+', keywords_json)
        keywords = [k for k in keywords if len(k) > 1 and k != "í‚¤ì›Œë“œ"]

    # í‚¤ì›Œë“œ ë¹„ì—ˆì„ ë•Œ ê¸°ë³¸ê°’
    if not keywords: keywords = ["ë¯¼ë²•", "í–‰ì •"]
    
    callback(30, f"ğŸ” ({model_src}) ê²€ìƒ‰ì–´: {', '.join(keywords)}")
    
    # 2. [Action] ê³„ì¸µì  ê²€ìƒ‰ ì „ëµ (Layered Search)
    candidates = search_candidates_from_api(keywords)
    
    # ì „ëµ B: 1ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ 'ìƒí™© í…ìŠ¤íŠ¸' ì¼ë¶€ë¡œ ê´‘ì—­ ê²€ìƒ‰
    if not candidates:
        callback(40, "âš ï¸ ì •ë°€ ê²€ìƒ‰ ì‹¤íŒ¨. ê´‘ì—­ ê²€ìƒ‰ ì‹œë„...")
        broad_keywords = ["ê³µë™ì£¼íƒ", "ì§‘í•©ê±´ë¬¼", "ë„ë¡œêµí†µ", "ê²½ë²”ì£„", "ë¯¼ë²•"]
        # ìƒí™© í…ìŠ¤íŠ¸ ì• 10ê¸€ìì—ì„œ ëª…ì‚¬í˜• ì¶”ì • ë‹¨ì–´ ì¶”ì¶œ
        sim_kw = situation[:15].replace(" ", "")
        candidates = search_candidates_from_api([sim_kw]) + search_candidates_from_api(broad_keywords)
        
    # ì „ëµ C: ìµœí›„ì˜ ë³´ë£¨ (ì ˆëŒ€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¦¬í„´í•˜ì§€ ì•ŠìŒ)
    if not candidates:
        candidates = ["ë¯¼ë²•", "í–‰ì •ì ˆì°¨ë²•", "ê³µë™ì£¼íƒê´€ë¦¬ë²•"]

    callback(50, f"âš–ï¸ ìµœì  ë²•ë ¹ ì„ ë³„ ì¤‘... (í›„ë³´: {len(candidates)}ê°œ)")
    
    # 3. [Selection] AIê°€ í›„ë³´ ì¤‘ ìµœì  ë²•ë ¹ ì„ íƒ
    prompt_sel = f"""
    [ë¯¼ì› ìƒí™©] {situation}
    [ê²€ìƒ‰ëœ ì‹¤ì¡´ ë²•ë ¹ í›„ë³´] {', '.join(candidates)}
    
    ìœ„ í›„ë³´ ì¤‘ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ë²•ë ¹ 1ê°œì˜ 'ì •í™•í•œ ì´ë¦„'ë§Œ ì¶œë ¥í•´.
    """
    best_law_name, _ = generate_content_hybrid(prompt_sel)
    best_law_name = re.sub(r"[\"'\[\]]", "", best_law_name).strip()
    
    # í›„ë³´êµ° ë§¤ì¹­ (AI í™˜ê° ë°©ì§€)
    final_name = next((cand for cand in candidates if cand in best_law_name), candidates[0])
    
    callback(70, f"ğŸ“œ '{final_name}' ìƒì„¸ ì¡°ë¬¸ ì¶”ì¶œ ì¤‘...")
    
    # 4. [Retrieval] ìƒì„¸ ì¡°ë¬¸ ê°€ì ¸ì˜¤ê¸°
    try:
        search_url = f"https://www.law.go.kr/DRF/lawSearch.do?OC={LAW_API_ID}&target=law&type=XML&query={final_name}"
        root = ET.fromstring(requests.get(search_url, timeout=5).content)
        
        # ì •í™•ë„ ë³´ì •ì„ ìœ„í•´ ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ID ì‚¬ìš©
        try:
            mst = root.find(".//MST").text
        except:
             return final_name, "ë²•ë ¹ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API ì—°ë™ ì˜¤ë¥˜)"

        detail_url = f"https://www.law.go.kr/DRF/lawService.do?OC={LAW_API_ID}&target=law&MST={mst}&type=XML"
        detail_root = ET.fromstring(requests.get(detail_url, timeout=8).content)
        
        articles = []
        for a in detail_root.findall(".//ì¡°ë¬¸")[:100]: # ì¡°ë¬¸ 100ê°œ
            num = a.find('ì¡°ë¬¸ë²ˆí˜¸').text or ""
            cont = a.find('ì¡°ë¬¸ë‚´ìš©').text or ""
            sub_clauses = []
            for sub in a.findall(".//í•­"):
                s_num = sub.find('í•­ë²ˆí˜¸').text or ""
                s_cont = sub.find('í•­ë‚´ìš©').text or ""
                sub_clauses.append(f"  ({s_num}) {s_cont}")
            articles.append(f"[ì œ{num}ì¡°] {cont}\n" + "\n".join(sub_clauses))
            
        return final_name, "\n".join(articles)
    except Exception as e:
        return final_name, f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¡°ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}"

# --- 4. ê²€ìƒ‰ ë° ë³´ê³ ì„œ ì‘ì„± ---

def get_search_results(situation, callback):
    """ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰"""
    callback(80, "ğŸ” ìœ ì‚¬ í–‰ì • ì‹¬íŒ ë° íŒë¡€ ê²€ìƒ‰ ì¤‘...")
    try:
        params = {"engine": "google", "q": f"{situation} í–‰ì •ì²˜ë¶„ íŒë¡€", "api_key": SERPAPI_KEY, "num": 3}
        search = GoogleSearch(params)
        results = search.get_dict().get("organic_results", [])
        return "\n".join([f"- {item['title']}: {item['snippet']}" for item in results])
    except: return "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"

def generate_final_report(situation, law_name, law_text, search_text, callback):
    """ìµœì¢… ë³´ê³ ì„œ ì‘ì„±"""
    
    prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ í–‰ì • ì „ë¬¸ê´€ì…ë‹ˆë‹¤. 
    ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ [ê´€ë ¨ ë²•ë ¹ ë°ì´í„°]ë¥¼ ê·¼ê±°ë¡œ ë‹µë³€í•´ì•¼ í•˜ë©°, ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ë©´ ì•ˆ ë©ë‹ˆë‹¤.
    
    [ë¯¼ì› ë‚´ìš©] {situation}
    
    [ì ìš© ë²•ë ¹: {law_name}]
    {law_text}
    
    [ì°¸ê³  íŒë¡€]
    {search_text}
    
    ---
    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    ## ğŸ’¡ í•µì‹¬ ìš”ì•½
    (3ì¤„ ìš”ì•½)
    
    ## ğŸ“œ ë²•ì  ê²€í† 
    (ê°€ì¥ ì¤‘ìš”: ìœ„ ë²•ë ¹ ë°ì´í„°ì˜ 'ì œOì¡° ì œOí•­'ì„ êµ¬ì²´ì ìœ¼ë¡œ ì¸ìš©í•˜ì—¬ ì ë²•/ìœ„ë²• ì—¬ë¶€ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì„œìˆ )
    
    ## ğŸ‘£ ì¡°ì¹˜ ê³„íš
    (ë¯¼ì›ì¸ì´ ë°Ÿì•„ì•¼ í•  í–‰ì • ì ˆì°¨ ë° ëŒ€ì‘ ë°©ì•ˆ)
    
    ## ğŸ“„ ë‹µë³€ ì´ˆì•ˆ
    (ë¯¼ì›ì¸ì—ê²Œ ë³´ë‚¼ ì •ì¤‘í•˜ê³  ëª…í™•í•œ ë‹µë³€ ë©”ì‹œì§€)
    """
    
    callback(90, "ğŸ§  ì‹¬ì¸µ ë¶„ì„ ë° ë³´ê³ ì„œ ì‘ì„± ì¤‘...")
    res, source = generate_content_hybrid(prompt)
    callback(100, "ì™„ë£Œ!")
    return res, source

# --- 5. UI ì‹¤í–‰ ---

st.markdown(f"""
<div style="text-align:center; padding: 20px;">
    <h1 style="color:#1a237e;">âš–ï¸ AI í–‰ì •ê´€: The Legal Glass</h1>
    <div style="margin-top: 10px;">
        <span class="status-badge">Main: Gemini (2.0/1.5)</span>
        <span class="groq-badge">Backup: Groq (Llama 3.3 Expert)</span>
    </div>
</div>
""", unsafe_allow_html=True)

with st.container():
    st.markdown('<div style="height: 20px;"></div>', unsafe_allow_html=True)
    user_input = st.text_area("ë¯¼ì› ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”", height=120, placeholder="ì˜ˆ: ì•„íŒŒíŠ¸ ë‹¨ì§€ ë‚´ ê°œì¸í˜• ì´ë™ì¥ì¹˜(í‚¥ë³´ë“œ) ë¶ˆë²• ì£¼ì°¨ ìˆ˜ê±° ê°€ëŠ¥ ì—¬ë¶€")
    btn = st.button("ğŸš€ ì •ë°€ ë²•ë¦¬ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

if btn and user_input:
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_status(p, t):
        progress_bar.progress(p)
        status_text.caption(f"{t}")
        time.sleep(0.1)

    # 1. ì •ë°€ ë²•ë ¹ íƒìƒ‰ (Tenbagger Logic)
    law_name, law_text = get_law_context_advanced(user_input, update_status)
    
    # 2. íŒë¡€ ê²€ìƒ‰
    search_text = get_search_results(user_input, update_status)
    
    # 3. ë³´ê³ ì„œ ì‘ì„±
    final_text, used_source = generate_final_report(user_input, law_name, law_text, search_text, update_status)
    
    progress_bar.empty()
    status_text.empty()
    
    st.divider()
    
    # ê²°ê³¼ ì•Œë¦¼
    if "Groq" in used_source:
        st.warning(f"âš¡ êµ¬ê¸€ ì„œë²„ ê³¼ë¶€í•˜ë¡œ **{used_source}**ê°€ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.", icon="âš¡")
    elif used_source == "Fail":
        st.error(f"ë¶„ì„ ì‹¤íŒ¨: {final_text}")
    else:
        st.success(f"âœ¨ **{used_source}**ê°€ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. (ì ìš©ë²•ë ¹: {law_name})", icon="ğŸ¤–")

    # ê²°ê³¼ ì¶œë ¥
    sections = re.split(r'(?=## )', final_text)
    for section in sections:
        if not section.strip(): continue
        with st.container():
            st.markdown(section)

    # DB ì €ì¥ (ì˜µì…˜)
    if use_db and used_source != "Fail":
        try:
            supabase.table("law_reports").insert({
                "situation": user_input,
                "law_name": law_name,
                "summary": final_text[:500],
                "ai_model": used_source
            }).execute()
        except: pass
